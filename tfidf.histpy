import numpy as np
A = np.array((4,5))
A
A[3,4] = 7
A.shape
A = np.empty((4,5))
A[3,4] = 7
A
np.around(A, 3)
np.around(A)
np.around(A, decimals=3)
np.around(A, decimals=1)
A[3,4]
q
quit()
y
p = "/home/dicle/Dicle/Tez/geziyakurdiproject/texts/"
import nltk
%quickref
import /home/dicle/Dicle/Tez/workspace2/Crawling9Mart/sentimentfinding/IOtools
import /home/dicle/Dicle/Tez/workspace2/Crawling9Mart/sentimentfinding/IOtools.py
from /home/dicle/Dicle/Tez/workspace2/Crawling9Mart/sentimentfinding import IOtools
from /home/dicle/Dicle/Tez/workspace2/Crawling9Mart/sentimentfinding/ import IOtools
from home/dicle/Dicle/Tez/workspace2/Crawling9Mart/sentimentfinding/ import IOtools
from ..sentimentfinding import IOtools
from home.dicle.Dicle.Tez.workspace2.Crawling9Mart.sentimentfinding import IOtools
from Dicle.Tez.workspace2.Crawling9Mart.sentimentfinding import IOtools
quit()
y
from sentimentfinding import IOtools
rootpath = "/home/dicle/Dicle/Tez/geziyakurdiproject/corpus/"
import nltk
posids = IOtools.getfilenames_of_dir(rootpath+"/pos/",removeextension=False)
posids
negids = IOtools.getfilenames_of_dir(rootpath+"/neg/",removeextension=False)
labelids = {}
labelids["pos"] = posids
labelids["neg"] = negids
labelids
from txtprocessor import texter
docroots = []
for label,ids in labelids.iteritems():
    for fileid in ids:
        words = texter.read_article(rootpath+"/"+label+"/"+fileid)
        for word in words:
            docroots.append((fileid, word))
            
print len(docroots)
print len(docroots[0])
print docroots[0]
cfdDocRoot = nltk.ConditionalFreqDist(docroots)
cfdRootDoc = nltk.ConditionalFreDist((word, fileid) for fileid in cfdDocRoot.conditions() for word in list(cfdDocRoot[fileid])) 
cfdRootDoc = nltk.ConditionalFreqDist((word, fileid) for fileid in cfdDocRoot.conditions() for word in list(cfdDocRoot[fileid])) 
import pandas as pd
import numpy as np
def compute_tfidf():
def compute_tfidf():
    return
def compute_tfidf(cfd1, cfd2):
    
    nwords = len(cfd1.conditions())
    ndocs = len(cfd2.conditions())
    matrix = np.empty((ndocs, nwords))
def compute_tfidf(cfd1, cfd2):
    
    nwords = len(cfd1.conditions())
    ndocs = len(cfd2.conditions())
    matrix = np.empty((ndocs, nwords))
    for i,doc in enumerate(cfd2.conditions()):
        for j,term in enumerate(cfd1.conditions()):
            tf = cfd2[doc][term]
            idf = math.log(float(ndocs) / cfd1[term].N())
            matrix[i,j] = tf * idf
    doctermframe = pd.DataFrame(matrix, index=cfd2.conditions(), columns=cfd1.conditions())
    doctermframe.to_csv(rootpath+"/matrix/tfidfmatrix.csv")
    return doctermframe
import math
from datetime import datetime
start = datetime.now()
df = compute_tfidf(cfdRootDoc, cfdDocRoot)
df["neu15Haz-wallerstein_KurtlerinIkilemi.txt"]["bu"]
df[u"neu15Haz-wallerstein_KurtlerinIkilemi.txt"][u"bu"]
print type(df)
df2 = pd.DataFrame(df, columns=["kürt","kürtler","gezi","türkler"])
df2
df["pos6Haz-ezgi_KurtlerİleLaikçiTeyzelerYuvarlakDansta"]
df.columns
df.ix["apocu"]
df.ix["pos6Haz-ezgi_KurtlerİleLaikçiTeyzelerYuvarlakDansta"]
df.ix["pos6Haz-ezgi_KurtlerİleLaikçiTeyzelerYuvarlakDansta.txt"]
df["pos6Haz-ezgi_KurtlerİleLaikçiTeyzelerYuvarlakDansta.txt"]
%save tfidf8Tem
%save tfidf8Tem _
y
import readline
readline.write_history_file("tfidf.histpy")
